{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "# Imports \n",
    "#########################\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pypianoroll\n",
    "from pypianoroll import Multitrack, Track\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Constant \n",
    "#########################\n",
    "RESOLUTION = 24\n",
    "PITCH = 128\n",
    "TS = 4\n",
    "BAR = RESOLUTION\n",
    "MEASURE = BAR * TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Bar Collection\n",
    "#########################\n",
    "\"\"\"\n",
    "    Bar Collection:\n",
    "        A collection of multiple training points on the granularity of \n",
    "        a music bar.\n",
    "        \n",
    "        For simplicity we assume that all Midi input files share the\n",
    "        following properties\n",
    "        \n",
    "        Resolution: 24 (per beat)\n",
    "        Tempo: 120 bpm\n",
    "        Time Signature: 4/4\n",
    "        Note Pitch: [0-127] (128 possibilities)\n",
    "        # Tracks: 1 (Single-Track Midi)\n",
    "            - If Midi contains multiple tracks, use only 1st track\n",
    "        \n",
    "\"\"\"\n",
    "def midi_to_array(path):\n",
    "    \"\"\"\n",
    "        midi_to_array: Returns binarized midi represention of input file\n",
    "            as numpy.ndarry\n",
    "        \n",
    "        Args:\n",
    "            path(str): Path to target midi file\n",
    "        \n",
    "        Returns:\n",
    "            data (np.ndarry): Matrix representation of midi file\n",
    "    \"\"\"\n",
    "    # Import midi data to pypianoroll Multitrack\n",
    "    data = pypianoroll.read(path)\n",
    "\n",
    "    # Export Multitrack to numpy ndarray\n",
    "    data = data.stack() #(N x T x P)\n",
    "    \n",
    "    # Select 1st track if other tracks present\n",
    "    data = np.expand_dims(data[0,:,:], axis=0)\n",
    "    \n",
    "    # Set all velocity values to zero to binarize data\n",
    "    data[data >= 1] = 1\n",
    "    \n",
    "    return data\n",
    "\n",
    "def parse_data(datadir):\n",
    "    \"\"\"\n",
    "        parse_data: Reads all midi files from a directory to produce a\n",
    "            bar collection\n",
    "        \n",
    "        Args:\n",
    "            datadir(str): Directory to import data from\n",
    "        \n",
    "        Return:\n",
    "            bar_collection (np.ndarry: N x T x P): Resulting collection\n",
    "                from file directory\n",
    "        \n",
    "    \"\"\"\n",
    "    midi_list = []\n",
    "    \n",
    "    for root, dirs, filenames in os.walk(datadir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".mid\") or filename.endswith(\".midi\"):\n",
    "                path = os.path.join(root, filename)\n",
    "                midi_data = midi_to_array(path)\n",
    "                midi_list.append(midi_data)\n",
    "    \n",
    "    print(\"Loaded {} files from directory: {}\".format(len(midi_list), datadir))\n",
    "    \n",
    "    # Concatenate arrays allong time (T) dimension \n",
    "    bar_concat = np.concatenate(midi_list, axis=1) # (1 x T x H)\n",
    "    num_bars = bar_concat.shape[1] / RESOLUTION\n",
    "    \n",
    "    print(\"Resulting Collection has a total of {} bars\".format(int(num_bars)))\n",
    "    \n",
    "    # Process collection for training \n",
    "    bar_concat = np.transpose(bar_concat, axes=(0,2,1)) # (1 x H x T)\n",
    "    bars = np.array_split(bar_concat, num_bars, axis=2) # List (N): (H x W)\n",
    "    bars = [np.expand_dims(bar, axis=0) for bar in bars] # List (N): (1 x H x W)\n",
    "    bar_collection = np.concatenate(bars, axis=0) # (N, 1, H, W)\n",
    "    \n",
    "    return bar_collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Dataset\n",
    "#########################\n",
    "class BarDataset(Dataset):\n",
    "    def __init__(self, collection, step_size=BAR):\n",
    "        self.data, self.data_len = self.extract_data(collection)\n",
    "        self.step_size = step_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        X = self.data[idx]\n",
    "        X_prev = torch.zeros(X.shape).cuda() if idx == 0 else self.data[idx-1]\n",
    "        \n",
    "        return X, X_prev\n",
    "    \n",
    "    def extract_data(self, collection):\n",
    "        data_len = collection.shape[0]\n",
    "        \n",
    "        # Transform data to appropriate format\n",
    "        data = torch.Tensor(collection)\n",
    "        data = data.cuda()\n",
    "        \n",
    "        return data, data_len\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 files from directory: ../dataset\n",
      "Resulting Collection has a total of 542 bars\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Dataloader\n",
    "#########################\n",
    "train_data = parse_data(\"../dataset\")\n",
    "train_dataset = BarDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, \n",
    "                        num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Model Defintion \n",
    "###########################\n",
    "\n",
    "##########################\n",
    "# Model Helpers\n",
    "##########################\n",
    "\n",
    "def conv_prev_concat(x, y):\n",
    "        \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
    "        x_shapes = x.shape\n",
    "        y_shapes = y.shape\n",
    "        if x_shapes[2:] == y_shapes[2:]:\n",
    "            y2 = y.expand(x_shapes[0],y_shapes[1],x_shapes[2],x_shapes[3])\n",
    "\n",
    "            return torch.cat((x, y2),1)\n",
    "\n",
    "        else:\n",
    "            print(x_shapes[2:])\n",
    "            print(y_shapes[2:])\n",
    "\n",
    "\n",
    "##########################\n",
    "# Model Subunits\n",
    "##########################\n",
    "            \n",
    "class LConv2d(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k, s, p):\n",
    "        super(LConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(c_in, c_out, k, s, p, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lrelu(x)\n",
    "        return x\n",
    "    \n",
    "class ConvTranspose2d(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k, s, p):\n",
    "        super(ConvTranspose2d, self).__init__()\n",
    "        self.conv = nn.ConvTranspose2d(c_in, c_out, k, s, p, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "        \n",
    "           \n",
    "##########################\n",
    "# Model \n",
    "##########################        \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, gf_dim=64, nz=100, pitch_range=PITCH, bar_length=BAR):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Define class properties\n",
    "        self.gf_dim = gf_dim \n",
    "        self.nz = nz # length of input vector 'z' (noise signal)\n",
    "        self.pitch_range = pitch_range\n",
    "        self.num_filters = 256\n",
    "        \n",
    "        # Noise Projection Layer\n",
    "        self.h0_prev = LConv2d(c_in=1, c_out=self.num_filters, k=(1,pitch_range), s=(1,2), p=0)\n",
    "        self.h1_prev = LConv2d(c_in=self.num_filters, c_out=self.num_filters, k=(2,1), s=(2,2), p=0)\n",
    "        self.h2_prev = LConv2d(c_in=self.num_filters, c_out=self.num_filters, k=(2,1), s=(2,2), p=0)\n",
    "        self.h3_prev = LConv2d(c_in=self.num_filters, c_out=self.num_filters, k=(2,1), s=(2,2), p=0)\n",
    "        \n",
    "        # Conditions Layer\n",
    "        self.h1 = ConvTranspose2d(c_in=384, c_out=pitch_range, k=(2,1), s=(2,2), p=0)\n",
    "        self.h2 = ConvTranspose2d(c_in=384, c_out=pitch_range, k=(2,1), s=(2,2), p=0)\n",
    "        self.h3 = ConvTranspose2d(c_in=384, c_out=pitch_range, k=(2,1), s=(2,2), p=0)\n",
    "        self.h4 = ConvTranspose2d(c_in=384, c_out=1, k=(1,pitch_range), s=(1,2), p=0)\n",
    "        \n",
    "        # Linear Transformation layer\n",
    "        self.linear1 = nn.Linear(self.nz, 1024)\n",
    "        self.linear2 = nn.Linear(1024, self.gf_dim*3*2*1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, z, prev_x):\n",
    "        \n",
    "        prev_x = prev_x.permute(0,1,3,2)\n",
    "        b_size = prev_x.shape[0]\n",
    "        \n",
    "        # TODO: comment on shape of output\n",
    "        h0_prev = self.h0_prev(prev_x)\n",
    "        h1_prev = self.h1_prev(h0_prev)\n",
    "        h2_prev = self.h2_prev(h1_prev)\n",
    "        h3_prev = self.h3_prev(h2_prev)\n",
    "    \n",
    "        \n",
    "        # TODO: comment on shape of output\n",
    "        h0 = self.linear1(z)\n",
    "        \n",
    "        h1 = self.linear2(h0)\n",
    "        h1 = h1.view(b_size, self.gf_dim * 2, 3, 1)\n",
    "        h1 = conv_prev_concat(h1, h3_prev)\n",
    "        \n",
    "        h2 = self.h1(h1)\n",
    "        h2 = conv_prev_concat(h2, h2_prev)\n",
    "        \n",
    "        h3 = self.h2(h2)\n",
    "        h3 = conv_prev_concat(h3, h1_prev)\n",
    "        \n",
    "        h4 = self.h3(h3)\n",
    "        h4 = conv_prev_concat(h4, h0_prev)\n",
    "        \n",
    "        g_x = self.sigmoid(self.h4(h4))\n",
    "        \n",
    "        return g_x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, df_dim=64, dfc_dim=1024, pitch_range=PITCH, bar_length=BAR):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.df_dim = df_dim\n",
    "        self.dfc_dim = dfc_dim\n",
    "        self.pitch_range = pitch_range\n",
    "        self.linear_in = self.df_dim * 40 * 15 # (conv kernel output (H,W))\n",
    "        \n",
    "        self.h0 = LConv2d(c_in=1, c_out=64, k=(4,89), s=1, p=0)\n",
    "        self.h1 = LConv2d(c_in=64, c_out=64, k=(4,1), s=1, p=0)\n",
    "        self.h2 = LConv2d(c_in=64, c_out=64, k=(4,1), s=1, p=0)\n",
    "        \n",
    "        self.linear = nn.Linear(self.linear_in, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.permute(0,1,3,2)\n",
    "        b_size = x.shape[0]\n",
    "        \n",
    "        h0 = self.h0(x)\n",
    "        h1 = self.h1(h0)\n",
    "        h2 = self.h2(h1)\n",
    "        h2 = h2.reshape(b_size, self.linear_in)\n",
    "        h3 = self.linear(h2)\n",
    "        \n",
    "        h3_sigmoid = self.sigmoid(h3)\n",
    "        \n",
    "        return h3_sigmoid, h3     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/20][0/34] Loss_D: 1.2515 Loss_G: 7.4963 D(x): 0.5284 D(G(z)): 0.4490 / 0.0017\n",
      "[0/20][1/34] Loss_D: 0.2590 Loss_G: 6.7503 D(x): 0.8906 D(G(z)): 0.1184 / 0.0028\n",
      "[0/20][2/34] Loss_D: 0.7201 Loss_G: 6.1514 D(x): 0.7848 D(G(z)): 0.2937 / 0.0108\n",
      "[0/20][3/34] Loss_D: 1.3591 Loss_G: 7.2561 D(x): 0.7714 D(G(z)): 0.5076 / 0.0032\n",
      "[0/20][4/34] Loss_D: 2.3735 Loss_G: 6.2123 D(x): 0.4065 D(G(z)): 0.4733 / 0.0098\n",
      "[0/20][5/34] Loss_D: 3.7816 Loss_G: 4.9362 D(x): 0.1537 D(G(z)): 0.3078 / 0.0405\n",
      "[0/20][6/34] Loss_D: 2.4275 Loss_G: 4.7245 D(x): 0.4326 D(G(z)): 0.4979 / 0.0220\n",
      "[0/20][7/34] Loss_D: 2.7327 Loss_G: 5.0519 D(x): 0.7549 D(G(z)): 0.6809 / 0.0231\n",
      "[0/20][8/34] Loss_D: 0.8601 Loss_G: 9.1218 D(x): 0.8116 D(G(z)): 0.3035 / 0.0029\n",
      "[0/20][9/34] Loss_D: 1.8182 Loss_G: 8.6732 D(x): 0.5877 D(G(z)): 0.2120 / 0.0270\n",
      "[0/20][10/34] Loss_D: 2.0812 Loss_G: 8.0428 D(x): 0.6532 D(G(z)): 0.0551 / 0.0074\n",
      "[0/20][11/34] Loss_D: 1.1480 Loss_G: 7.8436 D(x): 0.8431 D(G(z)): 0.3504 / 0.0137\n",
      "[0/20][12/34] Loss_D: 0.4907 Loss_G: 8.8427 D(x): 0.8960 D(G(z)): 0.1256 / 0.0015\n",
      "[0/20][13/34] Loss_D: 0.6025 Loss_G: 9.7747 D(x): 0.9291 D(G(z)): 0.2438 / 0.0011\n",
      "[0/20][14/34] Loss_D: 0.4364 Loss_G: 13.1731 D(x): 0.8982 D(G(z)): 0.1763 / 0.0000\n",
      "[0/20][15/34] Loss_D: 0.3120 Loss_G: 13.4809 D(x): 0.8358 D(G(z)): 0.0031 / 0.0000\n",
      "[0/20][16/34] Loss_D: 1.5127 Loss_G: 10.5638 D(x): 0.7548 D(G(z)): 0.0074 / 0.0007\n",
      "[0/20][17/34] Loss_D: 0.6671 Loss_G: 9.6806 D(x): 0.8746 D(G(z)): 0.1836 / 0.0026\n",
      "[0/20][18/34] Loss_D: 1.0052 Loss_G: 9.2004 D(x): 0.8435 D(G(z)): 0.0958 / 0.0005\n",
      "[0/20][19/34] Loss_D: 0.9404 Loss_G: 11.4090 D(x): 0.9608 D(G(z)): 0.3298 / 0.0011\n",
      "[0/20][20/34] Loss_D: 0.5139 Loss_G: 16.8122 D(x): 0.7727 D(G(z)): 0.0544 / 0.0000\n",
      "[0/20][21/34] Loss_D: 0.1695 Loss_G: 16.9968 D(x): 0.8823 D(G(z)): 0.0010 / 0.0000\n",
      "[0/20][22/34] Loss_D: 0.8687 Loss_G: 15.7683 D(x): 0.8090 D(G(z)): 0.0107 / 0.0011\n",
      "[0/20][23/34] Loss_D: 1.1978 Loss_G: 10.8098 D(x): 0.7537 D(G(z)): 0.0564 / 0.0148\n",
      "[0/20][24/34] Loss_D: 0.0457 Loss_G: 9.1513 D(x): 0.9946 D(G(z)): 0.0363 / 0.0036\n",
      "[0/20][25/34] Loss_D: 0.4240 Loss_G: 10.1082 D(x): 0.9525 D(G(z)): 0.2118 / 0.0004\n",
      "[0/20][26/34] Loss_D: 0.4526 Loss_G: 13.1567 D(x): 0.9520 D(G(z)): 0.1550 / 0.0000\n",
      "[0/20][27/34] Loss_D: 0.3562 Loss_G: 15.5920 D(x): 0.8884 D(G(z)): 0.0083 / 0.0000\n",
      "[0/20][28/34] Loss_D: 0.0845 Loss_G: 17.6758 D(x): 0.9394 D(G(z)): 0.0041 / 0.0000\n",
      "[0/20][29/34] Loss_D: 0.1140 Loss_G: 18.3387 D(x): 0.9143 D(G(z)): 0.0001 / 0.0000\n",
      "[0/20][30/34] Loss_D: 0.0062 Loss_G: 15.2370 D(x): 0.9948 D(G(z)): 0.0010 / 0.0001\n",
      "[0/20][31/34] Loss_D: 0.0014 Loss_G: 15.4462 D(x): 0.9992 D(G(z)): 0.0006 / 0.0000\n",
      "[0/20][32/34] Loss_D: 0.0035 Loss_G: 14.9170 D(x): 0.9972 D(G(z)): 0.0007 / 0.0000\n",
      "[0/20][33/34] Loss_D: 0.0154 Loss_G: 13.9129 D(x): 0.9982 D(G(z)): 0.0124 / 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\handout1\\lib\\site-packages\\torch\\nn\\modules\\loss.py:529: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch: 0 Average lossD: 0.0572566458 average_lossG: 0.6869149804,average D(x): 0.0506629230,average D(G(z)): 0.0003557366 \n",
      "==> Epoch: 1 Average lossD: 0.0085725662 average_lossG: 1.3508708477,average D(x): 0.0611702494,average D(G(z)): 0.0003877791 \n",
      "==> Epoch: 2 Average lossD: 0.0035469340 average_lossG: 1.4223216772,average D(x): 0.0617936902,average D(G(z)): 0.0003178745 \n",
      "==> Epoch: 3 Average lossD: 0.0007312413 average_lossG: 1.0186474323,average D(x): 0.0626616772,average D(G(z)): 0.0002058314 \n",
      "==> Epoch: 4 Average lossD: 0.0007346997 average_lossG: 1.2449527979,average D(x): 0.0624997813,average D(G(z)): 0.0001418847 \n",
      "[5/20][0/34] Loss_D: 0.0010 Loss_G: 15.6672 D(x): 0.9999 D(G(z)): 0.0009 / 0.0009\n",
      "[5/20][1/34] Loss_D: 0.0003 Loss_G: 17.1600 D(x): 1.0000 D(G(z)): 0.0003 / 0.0003\n",
      "[5/20][2/34] Loss_D: 0.0005 Loss_G: 16.3178 D(x): 0.9999 D(G(z)): 0.0004 / 0.0004\n",
      "[5/20][3/34] Loss_D: 0.0026 Loss_G: 14.0006 D(x): 1.0000 D(G(z)): 0.0026 / 0.0026\n",
      "[5/20][4/34] Loss_D: 0.0003 Loss_G: 17.2448 D(x): 1.0000 D(G(z)): 0.0003 / 0.0003\n",
      "[5/20][5/34] Loss_D: 0.0033 Loss_G: 13.0595 D(x): 1.0000 D(G(z)): 0.0032 / 0.0031\n",
      "[5/20][6/34] Loss_D: 0.0010 Loss_G: 14.5397 D(x): 1.0000 D(G(z)): 0.0010 / 0.0010\n",
      "[5/20][7/34] Loss_D: 0.0002 Loss_G: 17.2086 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
      "[5/20][8/34] Loss_D: 0.0350 Loss_G: 12.1342 D(x): 1.0000 D(G(z)): 0.0304 / 0.0151\n",
      "[5/20][9/34] Loss_D: 0.0017 Loss_G: 14.0183 D(x): 1.0000 D(G(z)): 0.0017 / 0.0012\n",
      "[5/20][10/34] Loss_D: 0.0089 Loss_G: 10.3576 D(x): 1.0000 D(G(z)): 0.0088 / 0.0077\n",
      "[5/20][11/34] Loss_D: 0.0007 Loss_G: 14.5767 D(x): 1.0000 D(G(z)): 0.0007 / 0.0006\n",
      "[5/20][12/34] Loss_D: 0.0009 Loss_G: 13.0919 D(x): 1.0000 D(G(z)): 0.0009 / 0.0008\n",
      "[5/20][13/34] Loss_D: 0.0002 Loss_G: 16.1854 D(x): 1.0000 D(G(z)): 0.0002 / 0.0001\n",
      "[5/20][14/34] Loss_D: 0.0047 Loss_G: 10.7179 D(x): 1.0000 D(G(z)): 0.0047 / 0.0042\n",
      "[5/20][15/34] Loss_D: 0.0006 Loss_G: 13.0222 D(x): 1.0000 D(G(z)): 0.0006 / 0.0005\n",
      "[5/20][16/34] Loss_D: 0.0006 Loss_G: 13.7452 D(x): 1.0000 D(G(z)): 0.0006 / 0.0005\n",
      "[5/20][17/34] Loss_D: 0.0029 Loss_G: 10.8002 D(x): 1.0000 D(G(z)): 0.0029 / 0.0026\n",
      "[5/20][18/34] Loss_D: 0.0004 Loss_G: 13.0337 D(x): 1.0000 D(G(z)): 0.0004 / 0.0004\n",
      "[5/20][19/34] Loss_D: 0.0002 Loss_G: 14.1027 D(x): 1.0000 D(G(z)): 0.0002 / 0.0001\n",
      "[5/20][20/34] Loss_D: 0.0021 Loss_G: 10.9095 D(x): 1.0000 D(G(z)): 0.0021 / 0.0019\n",
      "[5/20][21/34] Loss_D: 0.0003 Loss_G: 11.6703 D(x): 1.0000 D(G(z)): 0.0003 / 0.0003\n",
      "[5/20][22/34] Loss_D: 0.0034 Loss_G: 10.5071 D(x): 0.9999 D(G(z)): 0.0033 / 0.0030\n",
      "[5/20][23/34] Loss_D: 0.0009 Loss_G: 10.9015 D(x): 1.0000 D(G(z)): 0.0009 / 0.0008\n",
      "[5/20][24/34] Loss_D: 0.0021 Loss_G: 10.6440 D(x): 1.0000 D(G(z)): 0.0021 / 0.0016\n",
      "[5/20][25/34] Loss_D: 0.0009 Loss_G: 9.3157 D(x): 1.0000 D(G(z)): 0.0009 / 0.0008\n",
      "[5/20][26/34] Loss_D: 0.0174 Loss_G: 10.2160 D(x): 1.0000 D(G(z)): 0.0153 / 0.0017\n",
      "[5/20][27/34] Loss_D: 0.0055 Loss_G: 10.2143 D(x): 0.9955 D(G(z)): 0.0009 / 0.0008\n",
      "[5/20][28/34] Loss_D: 0.0748 Loss_G: 14.7620 D(x): 0.9994 D(G(z)): 0.0438 / 0.0009\n",
      "[5/20][29/34] Loss_D: 0.0006 Loss_G: 19.0349 D(x): 0.9999 D(G(z)): 0.0005 / 0.0008\n",
      "[5/20][30/34] Loss_D: 0.0044 Loss_G: 15.3221 D(x): 0.9995 D(G(z)): 0.0039 / 0.0077\n",
      "[5/20][31/34] Loss_D: 0.0058 Loss_G: 18.0422 D(x): 0.9999 D(G(z)): 0.0056 / 0.0129\n",
      "[5/20][32/34] Loss_D: 0.0211 Loss_G: 19.3443 D(x): 0.9997 D(G(z)): 0.0202 / 0.0307\n",
      "[5/20][33/34] Loss_D: 0.0277 Loss_G: 14.3864 D(x): 0.9995 D(G(z)): 0.0265 / 0.0307\n",
      "==> Epoch: 5 Average lossD: 0.0004300789 average_lossG: 0.8602485061,average D(x): 0.0627173030,average D(G(z)): 0.0002529798 \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 8.00 GiB total capacity; 6.32 GiB already allocated; 16.75 MiB free; 6.58 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4ebf88d959aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;31m# Classify all fake batch with D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;31m# Calculate D's loss on the all-fake batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\handout1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-3dde0d74d99b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mh0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\handout1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-3dde0d74d99b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\handout1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\handout1\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m--> 131\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\handout1\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2012\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2014\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2015\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2016\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 8.00 GiB total capacity; 6.32 GiB already allocated; 16.75 MiB free; 6.58 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# Training Functions \n",
    "##########################\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "nz = 100\n",
    "\n",
    "# Model instantiation\n",
    "torch.cuda.empty_cache()\n",
    "modelG = Generator(nz=nz)\n",
    "modelD = Discriminator()\n",
    "modelG.to(device)\n",
    "modelD.to(device)\n",
    "\n",
    "# Model optimizers\n",
    "optG = torch.optim.Adam(modelG.parameters(), lr=lr)\n",
    "optD = torch.optim.Adam(modelD.parameters(), lr=lr)\n",
    "\n",
    "# Model Criterion\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Loss accumulators\n",
    "average_lossD = 0\n",
    "average_lossG = 0\n",
    "average_D_x   = 0\n",
    "average_D_G_z = 0\n",
    "\n",
    "lossD_list =  []\n",
    "lossD_list_all = []\n",
    "lossG_list =  []\n",
    "lossG_list_all = []\n",
    "D_x_list = []\n",
    "D_G_z_list = []\n",
    "\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(epochs):\n",
    "        sum_lossG = 0\n",
    "        sum_lossD = 0\n",
    "        sum_D_x = 0\n",
    "        sum_D_G_z = 0\n",
    "\n",
    "        for i, (X, X_prev) in enumerate(train_loader):\n",
    "            ############################\n",
    "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            ###########################\n",
    "\n",
    "            # train with real samples\n",
    "            modelD.zero_grad()\n",
    "            X = X.to(device)\n",
    "            X_prev = X_prev.to(device)\n",
    "\n",
    "            # Format batch\n",
    "            b_size = X.size(0)\n",
    "            label = torch.full((b_size,), real_label, dtype=torch.float, device=device) # Create real labels\n",
    "\n",
    "            # Forward pass real batch through D\n",
    "            X = X.permute(0,1,3,2) # Permutate tensor to produce correct shape\n",
    "            out, out_logits = modelD(X)\n",
    "\n",
    "            # Calculate loss on all-real batch\n",
    "            d_loss_real = criterion(out, label)\n",
    "\n",
    "            # Calculate gradients for D in backward pass\n",
    "            d_loss_real.backward(retain_graph=True)\n",
    "            D_x = out.mean().item()\n",
    "            sum_D_x += D_x \n",
    "\n",
    "            ## Train with all-fake batch\n",
    "            # Generate batch of latent vectors\n",
    "            noise = torch.randn(b_size, nz, device=device)\n",
    "\n",
    "            # Generate fake image batch with G\n",
    "            fake = modelG(noise, X_prev)\n",
    "            label.fill_(fake_label)\n",
    "\n",
    "            # Classify all fake batch with D\n",
    "            out, out_logits = modelD(fake.detach())\n",
    "\n",
    "            # Calculate D's loss on the all-fake batch\n",
    "            d_loss_fake = criterion(out, label)\n",
    "\n",
    "            # Calculate the gradients for this batch\n",
    "            d_loss_fake.backward(retain_graph=True)\n",
    "            D_G_z1 = out.mean().item()\n",
    "\n",
    "            # Add the gradients from the all-real and all-fake batches\n",
    "            errD = d_loss_real + d_loss_fake\n",
    "            errD = errD.item()\n",
    "\n",
    "            # Update D\n",
    "            sum_lossD += errD\n",
    "            optD.step()\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network: maximize log(D(G(z)))\n",
    "            ###########################\n",
    "            modelG.zero_grad()\n",
    "            label.fill_(real_label) # fake labels are real for generator cost\n",
    "\n",
    "            # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "            out, out_logits = modelD(fake)\n",
    "\n",
    "            # Calculate G's loss based on this output\n",
    "            errG = criterion(out, label)\n",
    "            sum_lossG += errG\n",
    "\n",
    "            # Calculate gradients for G\n",
    "            errG.backward(retain_graph=True)\n",
    "\n",
    "            D_G_z2 = out.mean().item()\n",
    "            sum_D_G_z += D_G_z2\n",
    "            # Update G\n",
    "            optG.step()\n",
    "\n",
    "            ############################\n",
    "            # (3) Update G network again: maximize log(D(G(z)))\n",
    "            # Done to mitigate strength of Discriminator model \n",
    "            ###########################\n",
    "            #modelG.zero_grad()\n",
    "            #label.fill_(real_label) \n",
    "\n",
    "            # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "            #out, out_logits = modelD(fake)\n",
    "\n",
    "            # Calculate G's loss based on this output\n",
    "            #errG = criterion(out, label)\n",
    "\n",
    "            # Calculate gradients for G\n",
    "            #errG.backward(retain_graph=True)\n",
    "\n",
    "            #D_G_z2 = out.mean().item()\n",
    "            #sum_D_G_z += D_G_z2\n",
    "            # Update G\n",
    "            #optG.step()\n",
    "\n",
    "            if epoch % 5 == 0:\n",
    "                print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "                      % (epoch, epochs, i, len(train_loader),\n",
    "                         errD, errG, D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "            del X\n",
    "            del X_prev\n",
    "            del out \n",
    "            del out_logits\n",
    "            del label\n",
    "            del fake\n",
    "            del noise\n",
    "            del errD\n",
    "            del errG\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        average_lossD = (sum_lossD / len(train_loader.dataset))\n",
    "        average_lossG = (sum_lossG / len(train_loader.dataset))\n",
    "        average_D_x = (sum_D_x / len(train_loader.dataset))\n",
    "        average_D_G_z = (sum_D_G_z / len(train_loader.dataset))\n",
    "\n",
    "        lossD_list.append(average_lossD)\n",
    "        lossG_list.append(average_lossG)            \n",
    "        D_x_list.append(average_D_x)\n",
    "        D_G_z_list.append(average_D_G_z)\n",
    "\n",
    "        print('==> Epoch: {} Average lossD: {:.10f} average_lossG: {:.10f},average D(x): {:.10f},average D(G(z)): {:.10f} '.format(epoch, average_lossD,average_lossG,average_D_x, average_D_G_z)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# scratch pad\n",
    "#############################\n",
    "\n",
    "gen = Generator()\n",
    "gen.to(device)\n",
    "batch_size = 1\n",
    "z = torch.randn(batch_size, 100, device=device)\n",
    "\n",
    "prev_x = torch.unsqueeze(train[0][0], dim=0)\n",
    "prev_x.shape\n",
    "\n",
    "t1 = gen.forward(z, prev_x, batch_size)\n",
    "print(t1.shape)\n",
    "\n",
    "dis = Discriminator()\n",
    "dis.to(device)\n",
    "\n",
    "dis.forward(t1, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
